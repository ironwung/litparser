"""
Document Parser CLI

ëª¨ë“  ì§€ì› í¬ë§·ì„ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” í†µí•© CLI

ì‚¬ìš©ë²•:
    litparser document.pdf
    litparser document.docx --tables
    litparser slides.pptx --outline
"""

import sys
import os
import argparse
from pathlib import Path


def main():
    parser = argparse.ArgumentParser(
        description='LitParser - PDF, DOCX, PPTX, HWPX, TXT, MD ì§€ì›',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ì§€ì› í¬ë§·:
  .pdf          PDF ë¬¸ì„œ
  .docx         Microsoft Word
  .pptx         Microsoft PowerPoint  
  .hwpx         í•œê¸€ (ê°œë°©í˜•)
  .txt, .md     í…ìŠ¤íŠ¸/ë§ˆí¬ë‹¤ìš´

ì¶œë ¥ í¬ë§·:
  --markdown    ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜
  --json        JSONìœ¼ë¡œ ë³€í™˜ (êµ¬ì¡°í™” ë°ì´í„°)

ì˜ˆì‹œ:
  litparser document.pdf
  litparser document.pdf --markdown
  litparser document.pdf --json --include-images
  litparser report.docx --tables
'''
    )
    
    parser.add_argument('file', help='ë¬¸ì„œ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--text', '-t', action='store_true', help='í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ')
    parser.add_argument('--all-text', '-a', action='store_true', help='ëª¨ë“  í˜ì´ì§€ ì²˜ë¦¬')
    parser.add_argument('--tables', action='store_true', help='í…Œì´ë¸” ì¶”ì¶œ')
    parser.add_argument('--images', action='store_true', help='ì´ë¯¸ì§€ ì •ë³´')
    parser.add_argument('--save', '-s', action='store_true', help='ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥')
    parser.add_argument('--output-dir', default='.', help='ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--outline', '-o', action='store_true', help='ë¬¸ì„œ êµ¬ì¡°/ê°œìš”')
    parser.add_argument('--info', '-i', action='store_true', help='ë¬¸ì„œ ì •ë³´')
    parser.add_argument('--analyze', action='store_true', help='ìƒì„¸ ë¶„ì„ (PDF)')
    parser.add_argument('--markdown', '--md', action='store_true', help='ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜')
    parser.add_argument('--json', '-j', action='store_true', help='JSONìœ¼ë¡œ ë³€í™˜')
    parser.add_argument('--include-images', action='store_true', help='ì¶œë ¥ì— ì´ë¯¸ì§€ í¬í•¨ (base64)')
    parser.add_argument('--page', '-p', type=int, help='íŠ¹ì • í˜ì´ì§€ (0ë¶€í„° ì‹œì‘)')
    parser.add_argument('--output', help='ì¶œë ¥ íŒŒì¼')
    
    args = parser.parse_args()
    
    filepath = Path(args.file)
    if not filepath.exists():
        print(f"ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}", file=sys.stderr)
        sys.exit(1)
    
    ext = filepath.suffix.lower()
    
    try:
        if ext == '.pdf':
            process_pdf(filepath, args)
        elif ext == '.docx':
            process_docx(filepath, args)
        elif ext == '.pptx':
            process_pptx(filepath, args)
        elif ext == '.hwpx':
            process_hwpx(filepath, args)
        elif ext in ['.txt', '.md', '.markdown']:
            process_text(filepath, args)
        elif ext in ['.doc', '.ppt', '.hwp']:
            print(f"ì˜¤ë¥˜: {ext} í¬ë§·ì€ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.", file=sys.stderr)
            print("ë°”ì´ë„ˆë¦¬ í¬ë§·ìœ¼ë¡œ ë³„ë„ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.", file=sys.stderr)
            sys.exit(1)
        else:
            print(f"ì˜¤ë¥˜: ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼ í˜•ì‹: {ext}", file=sys.stderr)
            sys.exit(1)
            
    except Exception as e:
        print(f"ì˜¤ë¥˜: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


def process_pdf(filepath, args):
    """PDF ì²˜ë¦¬"""
    from . import (
        parse_pdf, extract_text, extract_all_text,
        get_page_count, get_pages, extract_tables, extract_images,
        analyze_layout, is_tagged_pdf, save_image
    )
    
    doc = parse_pdf(str(filepath))
    page_count = get_page_count(doc)
    
    # Markdown/JSON ì¶œë ¥
    if args.markdown or args.json:
        from .output_formatter import pdf_to_output, to_markdown, to_json
        
        output = pdf_to_output(doc, include_images=args.include_images)
        output.filename = str(filepath)
        
        if args.markdown:
            result = to_markdown(output, include_images=args.include_images)
        else:
            result = to_json(output, include_images=args.include_images)
        
        _write_output(args, result)
        return
    
    print(f"PDF ë¶„ì„: {filepath}")
    print("=" * 60)
    print(f"ë²„ì „: PDF {doc.version}")
    print(f"ê°ì²´ ìˆ˜: {len(doc.objects)}")
    print(f"í˜ì´ì§€ ìˆ˜: {page_count}")
    
    if args.info:
        print(f"Tagged PDF: {is_tagged_pdf(doc)}")
        return
    
    # ìƒì„¸ ë¶„ì„ ëª¨ë“œ
    if args.analyze:
        _run_integrated_analysis(doc, args, page_count)
        return
    
    if args.outline:
        from . import get_document_outline
        print("\në¬¸ì„œ ê°œìš”:")
        try:
            outline = get_document_outline(doc)
            for level, text in outline:
                print("  " * (level - 1) + f"H{level}: {text}")
            if not outline:
                print("  (ê°œìš” ì—†ìŒ)")
        except:
            print("  (ê°œìš” ì—†ìŒ)")
        return
    
    if args.tables:
        pages = [args.page] if args.page is not None else range(page_count)
        for p in pages:
            tables = extract_tables(doc, p)
            if tables:
                print(f"\ní…Œì´ë¸” ê°ì§€ (í˜ì´ì§€ {p + 1})")
                print("-" * 60)
                print(f"ë°œê²¬ëœ í…Œì´ë¸”: {len(tables)}ê°œ")
                for i, t in enumerate(tables, 1):
                    print(f"\ní…Œì´ë¸” {i}: {t.rows}í–‰ x {t.cols}ì—´")
                    md = t.to_markdown()
                    lines = md.split('\n')
                    if len(lines) > 10:
                        print('\n'.join(lines[:8]))
                        print(f"   ... ({len(lines) - 8}í–‰ ë”)")
                    else:
                        print(md)
        return
    
    if args.images:
        images = extract_images(doc)
        print(f"\nì´ë¯¸ì§€: {len(images)}ê°œ")
        for i, img in enumerate(images, 1):
            print(f"  {i}. {img.width}x{img.height} {img.color_space} ({len(img.data)} bytes)")

            if args.save:
                os.makedirs(args.output_dir, exist_ok=True)
                filename = os.path.join(args.output_dir, f"img{i}_{img.obj_num}")
                if save_image(img, filename):
                    for ext in ['.jpg', '.jpeg', '.png', '.jp2']:
                        if os.path.exists(filename + ext):
                            print(f"     â†’ ì €ì¥: {filename + ext}")
                            break
        return
    
    # ê¸°ë³¸: í…ìŠ¤íŠ¸ ì¶”ì¶œ
    if args.page is not None:
        text = extract_text(doc, args.page)
        print(f"\n--- í˜ì´ì§€ {args.page + 1} ---")
        print(text)
    else:
        text = extract_all_text(doc)
        print(text)
    
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write(text)
        print(f"\nì €ì¥ë¨: {args.output}")


def _run_integrated_analysis(doc, args, page_count):
    """í†µí•© ë¶„ì„ ì‹¤í–‰"""
    from . import (
        extract_images, save_image, extract_tables, 
        analyze_page_layout, extract_text
    )
    
    # ì´ë¯¸ì§€ëŠ” ë¬¸ì„œ ì „ì²´ì—ì„œ í•œ ë²ˆë§Œ ì¶”ì¶œ
    all_images = extract_images(doc)
    image_pages = _map_images_to_pages(doc, all_images)
    
    # í˜ì´ì§€ ë²”ìœ„ ê²°ì •
    if args.all_text:
        pages_to_analyze = range(page_count)
    elif args.page is not None:
        pages_to_analyze = [args.page]
    else:
        pages_to_analyze = [0]  # ê¸°ë³¸: ì²« í˜ì´ì§€
    
    for page_num in pages_to_analyze:
        print()
        print("=" * 60)
        print(f"ğŸ“„ í˜ì´ì§€ {page_num + 1} / {page_count}")
        print("=" * 60)
        
        # 1. ë ˆì´ì•„ì›ƒ ë¶„ì„
        layout = analyze_page_layout(doc, page_num)
        print(f"\nğŸ“ ë ˆì´ì•„ì›ƒ: {layout.width:.0f}x{layout.height:.0f}, "
              f"{layout.columns}ì»¬ëŸ¼, {len(layout.blocks)}ë¸”ë¡")
        
        if layout.has_header:
            print("   í—¤ë” ìˆìŒ")
        if layout.has_footer:
            print("   í‘¸í„° ìˆìŒ")
        
        # 2. í…ìŠ¤íŠ¸ (ì½ê¸° ìˆœì„œëŒ€ë¡œ)
        print(f"\nğŸ“ í…ìŠ¤íŠ¸:")
        print("-" * 40)
        
        for block in layout.get_reading_order():
            block_type = block.block_type.value
            text = block.text.strip()
            if text:
                type_emoji = {
                    'title': 'ğŸ“Œ',
                    'heading': 'ğŸ“',
                    'paragraph': '  ',
                    'list_item': '  â€¢',
                    'header': 'ğŸ”¼',
                    'footer': 'ğŸ”½',
                    'caption': '  ',
                }.get(block_type, '  ')
                
                if len(text) > 80:
                    lines = [text[i:i+76] for i in range(0, len(text), 76)]
                    print(f"{type_emoji} {lines[0]}")
                    for line in lines[1:]:
                        print(f"     {line}")
                else:
                    print(f"{type_emoji} {text}")
        
        # 3. ì´ë¯¸ì§€
        page_images = image_pages.get(page_num, [])
        if page_images:
            print(f"\nğŸ–¼ï¸  ì´ë¯¸ì§€: {len(page_images)}ê°œ")
            for img in page_images:
                print(f"   - {img.width}x{img.height} {img.color_space}")
                
                if args.save:
                    os.makedirs(args.output_dir, exist_ok=True)
                    filename = os.path.join(args.output_dir, 
                                           f"page{page_num+1}_img{img.obj_num}")
                    if save_image(img, filename):
                        for ext in ['.jpg', '.jpeg', '.png', '.jp2']:
                            if os.path.exists(filename + ext):
                                print(f"     â†’ ì €ì¥: {filename + ext}")
                                break
        
        # 4. í…Œì´ë¸”
        tables = extract_tables(doc, page_num)
        if tables:
            print(f"\nğŸ“Š í…Œì´ë¸”: {len(tables)}ê°œ")
            for i, table in enumerate(tables):
                print(f"\n   í…Œì´ë¸” {i+1} ({table.rows}x{table.cols}):")
                md = table.to_markdown()
                for line in md.split('\n')[:5]:
                    print(f"   {line}")
                if table.rows > 5:
                    print(f"   ... ({table.rows - 5}í–‰ ë”)")
    
    print()
    print("=" * 60)
    print("ë¶„ì„ ì™„ë£Œ")


def _map_images_to_pages(doc, images):
    """ì´ë¯¸ì§€ë¥¼ í˜ì´ì§€ì— ë§¤í•‘"""
    from . import get_pages, PDFRef
    
    pages = get_pages(doc)
    image_pages = {}
    
    for page_num, page in enumerate(pages):
        resources = page.get('Resources', {})
        if isinstance(resources, PDFRef):
            resources = doc.objects.get((resources.obj_num, resources.gen_num), {})
        
        xobjects = resources.get('XObject', {})
        if isinstance(xobjects, PDFRef):
            xobjects = doc.objects.get((xobjects.obj_num, xobjects.gen_num), {})
        
        page_images = []
        for name, ref in xobjects.items():
            if isinstance(ref, PDFRef):
                for img in images:
                    if img.obj_num == ref.obj_num:
                        page_images.append(img)
                        break
        
        if page_images:
            image_pages[page_num] = page_images
    
    return image_pages


def process_docx(filepath, args):
    """DOCX ì²˜ë¦¬"""
    from .formats.docx_parser import parse_docx
    
    doc = parse_docx(str(filepath))
    
    # Markdown/JSON ì¶œë ¥
    if args.markdown or args.json:
        from .output_formatter import docx_to_output, to_markdown, to_json
        
        output = docx_to_output(doc, include_images=args.include_images)
        output.filename = str(filepath)
        
        if args.markdown:
            result = to_markdown(output, include_images=args.include_images)
        else:
            result = to_json(output, include_images=args.include_images)
        
        _write_output(args, result)
        return
    
    print(f"DOCX ë¶„ì„: {filepath}")
    print("=" * 60)
    
    if args.info:
        print(f"ì œëª©: {doc.title or '(ì—†ìŒ)'}")
        print(f"ì‘ì„±ì: {doc.author or '(ì—†ìŒ)'}")
        print(f"ë¬¸ë‹¨: {len(doc.paragraphs)}ê°œ")
        print(f"í…Œì´ë¸”: {len(doc.tables)}ê°œ")
        print(f"ì´ë¯¸ì§€: {len(doc.images)}ê°œ")
        return
    
    if args.outline:
        print("\në¬¸ì„œ ê°œìš”:")
        headings = doc.get_headings()
        if headings:
            for level, text in headings:
                print("  " * (level - 1) + f"H{level}: {text}")
        else:
            print("  (í—¤ë”© ì—†ìŒ)")
        return
    
    if args.tables:
        print(f"\ní…Œì´ë¸”: {len(doc.tables)}ê°œ")
        for i, t in enumerate(doc.tables, 1):
            print(f"\ní…Œì´ë¸” {i}:")
            print(t.to_markdown())
        return
    
    if args.images:
        print(f"\nì´ë¯¸ì§€: {len(doc.images)}ê°œ")
        for img in doc.images:
            print(f"  - {img.filename} ({img.content_type})")
        return
    
    text = doc.get_text()
    print(text)
    _save_text_output(args, text)


def process_pptx(filepath, args):
    """PPTX ì²˜ë¦¬"""
    from .formats.pptx_parser import parse_pptx
    
    doc = parse_pptx(str(filepath))
    
    # Markdown/JSON ì¶œë ¥
    if args.markdown or args.json:
        from .output_formatter import pptx_to_output, to_markdown, to_json
        
        output = pptx_to_output(doc, include_images=args.include_images)
        output.filename = str(filepath)
        
        if args.markdown:
            result = to_markdown(output, include_images=args.include_images)
        else:
            result = to_json(output, include_images=args.include_images)
        
        _write_output(args, result)
        return
    
    print(f"PPTX ë¶„ì„: {filepath}")
    print("=" * 60)
    print(f"ìŠ¬ë¼ì´ë“œ: {doc.slide_count}ê°œ")
    
    if args.info:
        print(f"ì œëª©: {doc.title or '(ì—†ìŒ)'}")
        print(f"ì‘ì„±ì: {doc.author or '(ì—†ìŒ)'}")
        print(f"ì´ë¯¸ì§€: {len(doc.images)}ê°œ")
        return
    
    if args.outline:
        print("\nìŠ¬ë¼ì´ë“œ ëª©ë¡:")
        for slide in doc.slides:
            print(f"  {slide.number}. {slide.title or '(ì œëª© ì—†ìŒ)'}")
        return
    
    if args.tables:
        for slide in doc.slides:
            if slide.tables:
                print(f"\nìŠ¬ë¼ì´ë“œ {slide.number} í…Œì´ë¸”: {len(slide.tables)}ê°œ")
                for i, t in enumerate(slide.tables, 1):
                    print(f"\ní…Œì´ë¸” {i}:")
                    print(t.to_markdown())
        return
    
    if args.images:
        print(f"\nì´ë¯¸ì§€: {len(doc.images)}ê°œ")
        for img in doc.images:
            print(f"  - {img.filename} ({img.content_type})")
        return
    
    if args.page is not None:
        if 0 <= args.page < len(doc.slides):
            slide = doc.slides[args.page]
            print(f"\n--- ìŠ¬ë¼ì´ë“œ {slide.number} ---")
            print(slide.get_text())
        else:
            print(f"ì˜¤ë¥˜: ìŠ¬ë¼ì´ë“œ ë²ˆí˜¸ ë²”ìœ„ ì´ˆê³¼ (0-{len(doc.slides) - 1})")
        return
    
    text = doc.get_text()
    print(text)
    _save_text_output(args, text)


def process_hwpx(filepath, args):
    """HWPX ì²˜ë¦¬"""
    from .formats.hwpx_parser import parse_hwpx
    
    doc = parse_hwpx(str(filepath))
    
    # Markdown/JSON ì¶œë ¥
    if args.markdown or args.json:
        from .output_formatter import hwpx_to_output, to_markdown, to_json
        
        output = hwpx_to_output(doc, include_images=args.include_images)
        output.filename = str(filepath)
        
        if args.markdown:
            result = to_markdown(output, include_images=args.include_images)
        else:
            result = to_json(output, include_images=args.include_images)
        
        _write_output(args, result)
        return
    
    print(f"HWPX ë¶„ì„: {filepath}")
    print("=" * 60)
    
    if args.info:
        print(f"ì œëª©: {doc.title or '(ì—†ìŒ)'}")
        print(f"ì‘ì„±ì: {doc.author or '(ì—†ìŒ)'}")
        print(f"ë¬¸ë‹¨: {len(doc.paragraphs)}ê°œ")
        print(f"í…Œì´ë¸”: {len(doc.tables)}ê°œ")
        print(f"ì´ë¯¸ì§€: {len(doc.images)}ê°œ")
        return
    
    if args.outline:
        print("\në¬¸ì„œ ê°œìš”:")
        headings = doc.get_headings()
        if headings:
            for level, text in headings:
                print("  " * (level - 1) + f"H{level}: {text}")
        else:
            print("  (í—¤ë”© ì—†ìŒ)")
        return
    
    if args.tables:
        print(f"\ní…Œì´ë¸”: {len(doc.tables)}ê°œ")
        for i, t in enumerate(doc.tables, 1):
            print(f"\ní…Œì´ë¸” {i}:")
            print(t.to_markdown())
        return
    
    if args.images:
        print(f"\nì´ë¯¸ì§€: {len(doc.images)}ê°œ")
        for img in doc.images:
            print(f"  - {img.filename} ({img.content_type})")
        return
    
    text = doc.get_text()
    print(text)
    _save_text_output(args, text)


def process_text(filepath, args):
    """TXT/MD ì²˜ë¦¬"""
    from .formats.text_parser import parse_text, parse_markdown, extract_text as txt_extract
    
    ext = filepath.suffix.lower()
    is_markdown = ext in ['.md', '.markdown']
    
    if is_markdown:
        doc = parse_markdown(str(filepath))
    else:
        doc = parse_text(str(filepath))
    
    # Markdown/JSON ì¶œë ¥
    if args.markdown or args.json:
        from .output_formatter import text_to_output, to_markdown, to_json
        
        output = text_to_output(doc, is_markdown=is_markdown)
        output.filename = str(filepath)
        
        if args.markdown:
            result = to_markdown(output)
        else:
            result = to_json(output)
        
        _write_output(args, result)
        return
    
    print(f"{'ë§ˆí¬ë‹¤ìš´' if is_markdown else 'í…ìŠ¤íŠ¸'} ë¶„ì„: {filepath}")
    print("=" * 60)
    
    if args.info:
        print(f"ì¤„ ìˆ˜: {len(doc.lines)}")
        print(f"ì¸ì½”ë”©: {doc.encoding}")
        if is_markdown and doc.headings:
            print(f"í—¤ë”©: {len(doc.headings)}ê°œ")
            print(f"ì½”ë“œë¸”ë¡: {len(doc.code_blocks)}ê°œ")
            print(f"ë§í¬: {len(doc.links)}ê°œ")
            print(f"ì´ë¯¸ì§€: {len(doc.images)}ê°œ")
        return
    
    if args.outline and is_markdown and doc.headings:
        print("\në¬¸ì„œ ê°œìš”:")
        for level, text in doc.headings:
            print("  " * (level - 1) + f"H{level}: {text}")
        return
    
    if is_markdown and not args.text:
        text = doc.content
    else:
        text = txt_extract(doc) if is_markdown else doc.content
    print(text)
    _save_text_output(args, text)


def _write_output(args, content):
    """ì¶œë ¥ (íŒŒì¼ ë˜ëŠ” stdout)"""
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"ì €ì¥ë¨: {args.output}", file=sys.stderr)
    else:
        print(content)


def _save_text_output(args, text):
    """í…ìŠ¤íŠ¸ ì¶œë ¥ íŒŒì¼ ì €ì¥"""
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write(text)
        print(f"\nì €ì¥ë¨: {args.output}")


if __name__ == '__main__':
    main()
